[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "COMP/STAT112 Notebook",
    "section": "",
    "text": "Welcome\nWelcome to my online portfolio for COMP/STAT112 course taken at Macalester College. Please, use the side bar on the left for navigation.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "bw/bw-uni.html",
    "href": "bw/bw-uni.html",
    "title": "\n1  Univariate Viz\n",
    "section": "",
    "text": "# Data on students in this class\nsurvey &lt;- read.csv(\"https://hash-mac.github.io/stat112site-s25/data/survey.csv\")\nhikes &lt;- read.csv(\"https://mac-stat.github.io/data/high_peaks.csv\")\n# World Cup data\nworld_cup &lt;- read.csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-11-29/worldcups.csv\")\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(viridisLite)\n\n\nggplot(hikes, aes(x = elevation)) +\ngeom_histogram(color = \"white\", binwidth = 200, fill = viridis(1)) +\nlabs(x = \"Elevation (feet)\", y = \"Number of hikes\", title = \"Number of Hikes of Each Elevation\", caption = \"Visualized by: Benjamin Weng\\nSource: Survey\") + theme_minimal()\n\n\n\nNumber of hikes on Each Elevation plotted on bar chart. 4000 ft is the most common hikes while 5300 is the least.\n\n\n\nUse this file to generate a professional looking univariate visualization. The visualization will not perfect the first time but you are expected to improve on it throughout the semester especially after covering advanced topics such as effective viz.",
    "crumbs": [
      "Best Work",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Univariate Viz</span>"
    ]
  },
  {
    "objectID": "bw/bw-bi.html",
    "href": "bw/bw-bi.html",
    "title": "\n2  Bivariate Viz\n",
    "section": "",
    "text": "library(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\n\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\n\n\nAttaching package: 'mosaic'\n\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(fivethirtyeight)\n\nSome larger datasets need to be installed separately, like senators and\nhouse_district_forecast. To install these, we recommend you install the\nfivethirtyeightdata package by running:\ninstall.packages('fivethirtyeightdata', repos =\n'https://fivethirtyeightdata.github.io/drat/', type = 'source')\n\nlibrary(viridisLite)\n\n\ndata(bechdel)\nnew_bechdel &lt;- bechdel |&gt;\n  mutate(clean_test = factor(clean_test, c(\"nowomen\", \"notalk\", \"men\", \"dubious\", \"ok\"))) |&gt;\n  mutate(half_decades = cut(year, breaks = seq(1969, 2014, by = 5)))\n\n\nggplot(new_bechdel, aes(x = half_decades, fill = clean_test)) + labs(x = \"Half Decades\", y = \"Percentage (%)\", fill = \"Legend\", caption = (\"Visualized by: Benjamin Weng\\n Source: Five Thrity-Eight\"), title = \"The Bechdel Test results every half decade\") + geom_bar(position = \"fill\", width = 0.75) + scale_fill_manual(values = viridis(5), labels = c(\"nowomen\" = \"No Women\",  \"notalk\" = \"No Talk Between Women\",  \"men\" = \"Only Talk About Men\",  \"dubious\" = \"Dubious Pass\",  \"ok\" = \"Passes Bechdel Test\" )) + theme_minimal()\n\n\n\nPercentage of Bechdel Test results every half decade.No talk between women is always the most prominent failing factor, but has decreased over time.\n\n\n\nUse this file to generate a professional looking bivariate visualization. The visualization will not perfect the first time but you are expected to improve it throughout the semester especially after covering advanced topics such as effective viz.",
    "crumbs": [
      "Best Work",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Bivariate Viz</span>"
    ]
  },
  {
    "objectID": "bw/bw-tri.html",
    "href": "bw/bw-tri.html",
    "title": "\n3  Trivariate Viz\n",
    "section": "",
    "text": "education &lt;- read.csv(\"https://mac-stat.github.io/data/sat.csv\")\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(viridisLite)\n\n\nggplot(education, aes(x = expend, y = sat, color = fracCat)) + geom_point() + geom_smooth(method = \"lm\") + theme_minimal() + labs(x = \"Expend on Education\", y = \"Average SAT Score\", color = \"Percentage of students taking SAT\", title = \"Percentage of students who Take SAT, Expend on Education, and Average SAT\", caption = \"Visualized by: Benjamin Weng\\nSource: Education\") + scale_color_viridis_d()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\nPercentage of students taking SAT has a stronger correlation to Average SAT than that of Expend on Education.\n\n\n\nUse this file to generate a professional looking trivariate visualization. The visualization will not perfect the first time but you are expected to improve on it throughout the semester especially after covering advanced topics such as effective viz.",
    "crumbs": [
      "Best Work",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Trivariate Viz</span>"
    ]
  },
  {
    "objectID": "bw/bw-quad.html",
    "href": "bw/bw-quad.html",
    "title": "\n4  Quadvariate Viz\n",
    "section": "",
    "text": "── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\nggplot(weather, aes(y = temp3pm, x = temp9am, color = location, size = rainfall)) + \n  geom_point() + \n  labs(x = \"9 AM Temperature (°C)\", y = \"3 PM Temperature (°C)\", title = \"Temperature at 9AM, 3AM, and Rainfall at Three Locations\", color = \"Island\", size = \"Rainfall(mm)\", caption = \"Visualized by: Benjamin Weng\\nSource: Weather\") + theme_minimal() + scale_color_viridis_d()\n\nWarning: Removed 69 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\nAt three locations, temperature at 9 AM is positively correlated to 3 AM and seems to be inversely correlated to rainfall.\n\n\n\nUse this file to generate a professional looking quadvariate visualization. The visualization will not perfect the first time but you are expected to improve on it throughout the semester especially after covering advanced topics such as effective viz.",
    "crumbs": [
      "Best Work",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Quadvariate Viz</span>"
    ]
  },
  {
    "objectID": "bw/bw-spatial.html",
    "href": "bw/bw-spatial.html",
    "title": "\n5  Spatial Viz\n",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(openintro)\n\nLoading required package: airports\nLoading required package: cherryblossom\nLoading required package: usdata\n\nlibrary(maps)\n\n\nAttaching package: 'maps'\n\nThe following object is masked from 'package:purrr':\n\n    map\n\nlibrary(ggthemes)\nlibrary(viridisLite)\nstarbucks &lt;- read.csv(\"https://mac-stat.github.io/data/starbucks.csv\")\n\n\nstarbucks_us_by_state &lt;- starbucks |&gt;\n  filter(Country == \"US\") |&gt;\n  count(State.Province) |&gt;\n  mutate(state_name = str_to_lower(abbr2state(State.Province)))\n\n\ncensus_pop_est_2018 &lt;- read_csv(\"https://mac-stat.github.io/data/us_census_2018_state_pop_est.csv\") |&gt;\n  separate(state, into = c(\"dot\", \"state\"), extra = \"merge\") |&gt;\n  select(-dot) |&gt;\n  mutate(state = str_to_lower(state))\n\nRows: 51 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): state\ndbl (1): est_pop_2018\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nstarbucks_with_2018_pop_est &lt;-\n  starbucks_us_by_state |&gt;\n  left_join(census_pop_est_2018,\n    by = c(\"state_name\" = \"state\")\n  ) |&gt;\n  mutate(starbucks_per_10000 = (n / est_pop_2018) * 10000)\n\n\nstates_map &lt;- map_data(\"state\")\nstarbucks_contiguous_us &lt;- starbucks |&gt;\n  filter(Country == \"US\", State.Province != \"AK\", State.Province != \"HI\")\nggplot(starbucks_with_2018_pop_est, aes(map_id = state_name, fill = starbucks_per_10000)) +\n  geom_map(map = states_map) +\n  expand_limits(x = states_map$long, y = states_map$lat) +\n  geom_point(\n    data = starbucks_contiguous_us,\n    aes(x = Longitude, y = Latitude),\n    size = 0.05,\n    alpha = 0.2,\n    inherit.aes = FALSE) + \n  theme_map() +  scale_fill_gradientn(name = \"starbucks per 10000\", colors = viridis(2), values = scales::rescale(seq(0, 100, by = 5))) + labs(title = \"Starbucks per 10000 in continental US\", caption = \"Visualized by Benjamin Weng\\nSource: Starbucks\")\n\n\n\n\n\n\n\nUse this file to generate a professional looking spatial visualization. The visualization will not perfect the first time but you are expected to improve on it throughout the semester especially after covering advanced topics such as effective viz.",
    "crumbs": [
      "Best Work",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Spatial Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-uni.html",
    "href": "ica/ica-uni.html",
    "title": "\n6  Univariate Viz\n",
    "section": "",
    "text": "6.0.1 Import data\n\nhikes &lt;- read.csv(\"https://mac-stat.github.io/data/high_peaks.csv\")\n\n\nlibrary(tidyverse)\n\nExercise 1: Research Questions\nLet’s dig into the hikes data, starting with the elevation and difficulty ratings of the hikes:\n\nWhat features would we like a visualization of the categorical difficulty rating variable to capture?\n\nUsing a bar chart for the three categories: easy, moderate, and difficult.\n\nWhat about a visualization of the quantitative elevation variable?\n\nUse a histogram to show the difference in heights.\nExercise 2: Load tidyverse\nWe’ll address the above questions using ggplot tools. Try running the following chunk and simply take note of the error message – this is one you’ll get a lot!\n\n# Use the ggplot function\nggplot(hikes, aes(x = rating))\n\n\n\n\n\n\n\nIn order to use ggplot tools, we have to first load the tidyverse package in which they live. We’ve installed the package but we need to tell R when we want to use it. Run the chunk below to load the library. You’ll need to do this within any .qmd file that uses ggplot().\n\nlibrary(tidyverse)\n\nExercise 3: Bar Chart of Ratings - Part 1\nConsider some specific research questions about the difficulty rating of the hikes:\n\nHow many hikes fall into each category?\n\nThree on ‘moderate’, two on ‘difficult’, and one on ‘easy’\n\nAre the hikes evenly distributed among these categories, or are some more common than others?\n\nModerate is more common than easy.\nAll of these questions can be answered with: (1) a bar chart; of (2) the categorical data recorded in the rating column. First, set up the plotting frame:\n\nggplot(hikes, aes(x = rating))\n\n\n\n\n\n\n\nThink about:\n\nWhat did this do? What do you observe?\n\nGenerates an empty bar chart with all categories in ‘rating’ on x-axis\n\nWhat, in general, is the first argument of the ggplot() function?\n\nThe dataset used for plot\n\nWhat is the purpose of writing x = rating?\n\nAssigns the x-axis to the category ‘rating’\n\nWhat do you think aes stands for?!?\n\nAesthetics\nExercise 4: Bar Chart of Ratings - Part 2\nNow let’s add a geometric layer to the frame / canvas, and start customizing the plot’s theme. To this end, try each chunk below, one by one. In each chunk, make a comment about how both the code and the corresponding plot both changed.\nNOTE:\n\nPay attention to the general code properties and structure, not memorization.\nNot all of these are “good” plots. We’re just exploring ggplot.\n\n\n# geom_bar is added to the ggplot function; three bars were created with a y-axis defaulted as 'count'\nggplot(hikes, aes(x = rating)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n# labs() function is added. It labels the x and y axis\nggplot(hikes, aes(x = rating)) +\n  geom_bar() +\n  labs(x = \"Rating\", y = \"Number of hikes\")\n\n\n\n\n\n\n\n\n# fill = \"blue\" is added into the geom_bar as an argument. It fills the color(string) into the bar.\nggplot(hikes, aes(x = rating)) +\n  geom_bar(fill = \"blue\") +\n  labs(x = \"Rating\", y = \"Number of hikes\")\n\n\n\n\n\n\n\n\n# color = \"orange\" is added to geom_bar as an argument. It colors the frames of the bars.\nggplot(hikes, aes(x = rating)) +\n  geom_bar(color = \"orange\", fill = \"blue\") +\n  labs(x = \"Rating\", y = \"Number of hikes\")\n\n\n\n\n\n\n\n\n# theme_minimal() is added. It changes the background color to white\nggplot(hikes, aes(x = rating)) +\n  geom_bar(color = \"orange\", fill = \"blue\")  +\n  labs(x = \"Rating\", y = \"Number of hikes\") +\n  theme_minimal()\n\n\n\n\n\n\n\nExercise 5: Bar Chart Follow-up\nPart a\nReflect on the ggplot() code.\n\nWhat’s the purpose of the +? When do we use it?\n\nAdd an element to the graph.\n\nWe added the bars using geom_bar()? Why “geom”?\n\nGeom mean geometry. Geometry\n\nWhat does labs() stand for?\n\nLabels\n\nWhat’s the difference between color and fill?\n\nFill is filling the inside of something, while color only changes the color of the outline.\nPart b\nIn general, bar charts allow us to examine the following properties of a categorical variable:\n\n\nobserved categories: What categories did we observe?\n\nrating of easy, moderate, and difficult\n\n\nvariability between categories: Are observations evenly spread out among the categories, or are some categories more common than others?\n\nModerate difficulty mountains are the most common, followed by easy. Difficult mountain is very rare.\nWe must then translate this information into the context of our analysis, here hikes in the Adirondacks. Summarize below what you learned from the bar chart, in context.\nPart c\nIs there anything you don’t like about this barplot? For example: check out the x-axis again.\nIt would be better if it were easy-moderate-difficult.\nExercise 6: Sad Bar Chart\nLet’s now consider some research questions related to the quantitative elevation variable:\n\nAmong the hikes, what’s the range of elevation and how are the hikes distributed within this range (e.g. evenly, in clumps, “normally”)?\nWhat’s a typical elevation?\nAre there any outliers, i.e. hikes that have unusually high or low elevations?\n\nHere:\n\nConstruct a bar chart of the quantitative elevation variable.\n\n\nggplot(hikes, aes(x = elevation)) +\n  geom_bar(color = \"orange\", fill = \"blue\")  +\n  labs(x = \"Elevation\", y = \"Number of hikes\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nExplain why this might not be an effective visualization for this and other quantitative variables. (What questions does / doesn’t it help answer?)\n\nThere are too many different heights.\nExercise 7: A Histogram of Elevation\nQuantitative variables require different viz than categorical variables. Especially when there are many possible outcomes of the quantitative variable. It’s typically insufficient to simply count up the number of times we’ve observed a particular outcome as the bar graph did above. It gives us a sense of ranges and typical outcomes, but not a good sense of how the observations are distributed across this range. We’ll explore two methods for graphing quantitative variables: histograms and density plots.\nHistograms are constructed by (1) dividing up the observed range of the variable into ‘bins’ of equal width; and (2) counting up the number of cases that fall into each bin. Check out the example below:\n\nPart a\nLet’s dig into some details.\n\nHow many hikes have an elevation between 4500 and 4700 feet?\n\n6\n\nHow many total hikes have an elevation of at least 5100 feet?\n\n3\nPart b\nNow the bigger picture. In general, histograms allow us to examine the following properties of a quantitative variable:\n\n\ntypical outcome: Where’s the center of the data points? What’s typical?\n\n4700ft\n\n\nvariability & range: How spread out are the outcomes? What are the max and min outcomes?\n\nIt is clumped to the lower elevation region. Max is 3900-4100, 10, min is 5100-5300, 1\n\n\nshape: How are values distributed along the observed range? Is the distribution symmetric, right-skewed, left-skewed, bi-modal, or uniform (flat)?\n\nleft-skewed\n\n\noutliers: Are there any outliers, i.e. outcomes that are unusually large/small?\n\nNo.\nWe must then translate this information into the context of our analysis, here hikes in the Adirondacks. Addressing each of the features in the above list, summarize below what you learned from the histogram, in context.\nThe elevations are unevenly distributed. It is skewed to be lower and there are no significant outliers\nExercise 8: Building Histograms - Part 1\n2-MINUTE CHALLENGE: Thinking of the bar chart code, try to intuit what line you can tack on to the below frame of elevation to add a histogram layer. Don’t forget a +. If it doesn’t come to you within 2 minutes, no problem – all will be revealed in the next exercise.\n\nggplot(hikes, aes(x = elevation)) + geom_histogram()\n\n\n\n\n\n\n\nExercise 9: Building Histograms - Part 2\nLet’s build some histograms. Try each chunk below, one by one. In each chunk, make a comment about how both the code and the corresponding plot both changed.\n\n# Creates a histogram\nggplot(hikes, aes(x = elevation)) +\n  geom_histogram()\n\n\n\n\n\n\n\n\n# Let the boundary of the bars become white.\nggplot(hikes, aes(x = elevation)) +\n  geom_histogram(color = \"white\") \n\n\n\n\n\n\n\n\n# Fill the inside of the bard blue\nggplot(hikes, aes(x = elevation)) +\n  geom_histogram(color = \"white\", fill = \"blue\") \n\n\n\n\n\n\n\n\n# Change the x-axis and y-axis\nggplot(hikes, aes(x = elevation)) +\n  geom_histogram(color = \"white\") +\n  labs(x = \"Elevation (feet)\", y = \"Number of hikes\")\n\n\n\n\n\n\n\n\n# Change the width of each interval to 1000.\nggplot(hikes, aes(x = elevation)) +\n  geom_histogram(color = \"white\", binwidth = 1000) +\n  labs(x = \"Elevation (feet)\", y = \"Number of hikes\")\n\n\n\n\n\n\n\n\n# Change the interval to 5 \nggplot(hikes, aes(x = elevation)) +\n  geom_histogram(color = \"white\", binwidth = 5) +\n  labs(x = \"Elevation (feet)\", y = \"Number of hikes\")\n\n\n\n\n\n\n\n\n# Change the interval to 200\nggplot(hikes, aes(x = elevation)) +\n  geom_histogram(color = \"white\", binwidth = 200) +\n  labs(x = \"Elevation (feet)\", y = \"Number of hikes\")\n\n\n\n\n\n\n\nExercise 10: Histogram Follow-up\n\nWhat function added the histogram layer / geometry?\n\ngeom_histogram()\n\nWhat’s the difference between color and fill?\n\nColor is for the borders of the bars, while fill is for the interior\n\nWhy does adding color = \"white\" improve the visualization?\n\nIt separates the bars.\n\nWhat did binwidth do?\n\nChange the intervals in between bars.\n\nWhy does the histogram become ineffective if the binwidth is too big (e.g. 1000 feet)?\n\nBecause there are too few categories\n\nWhy does the histogram become ineffective if the binwidth is too small (e.g. 5 feet)?\n\nThere are too many categories\nExercise 11: Density Plots\nDensity plots are essentially smooth versions of the histogram. Instead of sorting observations into discrete bins, the “density” of observations is calculated across the entire range of outcomes. The greater the number of observations, the greater the density! The density is then scaled so that the area under the density curve always equals 1 and the area under any fraction of the curve represents the fraction of cases that lie in that range.\nCheck out a density plot of elevation. Notice that the y-axis (density) has no contextual interpretation – it’s a relative measure. The higher the density, the more common are elevations in that range.\n\nggplot(hikes, aes(x = elevation)) +\n  geom_density()\n\n\n\n\n\n\n\nQuestions\n\nINTUITION CHECK: Before tweaking the code and thinking back to geom_bar() and geom_histogram(), how do you anticipate the following code will change the plot?\n\nLine will be blue and area under curve will be orange.\n-   `geom_density(color = \"blue\")`\n-   `geom_density(fill = \"orange\")`\n\nTRY IT! Test out those lines in the chunk below. Was your intuition correct?\n\n\nggplot(hikes, aes(x = elevation)) +\n  geom_density(color = \"blue\", fill = \"orange\")\n\n\n\n\n\n\n\n\nExamine the density plot. How does it compare to the histogram? What does it tell you about the typical elevation, variability / range in elevations, and shape of the distribution of elevations within this range?\n\nIt is continuous compared to the density. The most typical elebation is around 4200 fts. Range is from around 3800-5300. Shape is skewed to the left.\nExercise 12: Density Plots vs Histograms\nThe histogram and density plot both allow us to visualize the behavior of a quantitative variable: typical outcome, variability / range, shape, and outliers. What are the pros/cons of each? What do you like/not like about each?\nHistograms give exact number of all elevation, but doesn’t give a continuous graph. Density gives continuous graph. But it is less straighforward in terms of number of each category.\nExercise 13: Code = communication\nWe obviously won’t be done until we talk about communication. All code above has a similar general structure (where the details can change):\n\nggplot(___, aes(x = ___)) + \n  geom___(color = \"___\", fill = \"___\") + \n  labs(x = \"___\", y = \"___\")\n\n\nThough not necessary to the code working, it’s common, good practice to indent or tab the lines of code after the first line (counterexample below). Why?\n\nThe style of the code is bad without indents\n\nggplot(hikes, aes(x = elevation)) +\ngeom_histogram(color = \"white\", binwidth = 200) +\nlabs(x = \"Elevation (feet)\", y = \"Number of hikes\")\n\n\n\n\n\n\n\n\nThough not necessary to the code working, it’s common, good practice to put a line break after each + (counterexample below). Why?\n\nEach line is too long to read without line breaks.\n\n# YUCK \nggplot(hikes, aes(x = elevation)) + geom_histogram(color = \"white\", binwidth = 200) + labs(x = \"Elevation (feet)\", y = \"Number of hikes\")\n\n\n\n\n\n\n\nExercise 14: Practice\nPart a\nPractice your viz skills to learn about some of the variables in one of the following datasets from the previous class:\n\n# Data on students in this class\nsurvey &lt;- read.csv(\"https://hash-mac.github.io/stat112site-s25/data/survey.csv\")\n\n# World Cup data\nworld_cup &lt;- read.csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-11-29/worldcups.csv\")\n\n\n  ggplot(world_cup, aes(x = host)) + geom_bar(color = \"brown\")\n\n\n\n\n\n\n\nPart b\nCheck out the RStudio Data Visualization cheat sheet to learn more features of ggplot.\n\n\n\n\n\n\nCheck → Commit → Push\n\n\n\nWhen done, don’t forgot to click Render Book and check the resulting HTML files. If happy, jump to GitHub Desktop and commit the changes with the message Finish activity 3 and push to GitHub. Wait few seconds, then visit your portfolio website and make sure the changes are there.",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Univariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-bi.html",
    "href": "ica/ica-bi.html",
    "title": "\n7  Bivariate Viz\n",
    "section": "",
    "text": "Exercise 0: Review",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Bivariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-bi.html#exercises-optional",
    "href": "ica/ica-bi.html#exercises-optional",
    "title": "\n7  Bivariate Viz\n",
    "section": "\n7.1 Exercises (optional)",
    "text": "7.1 Exercises (optional)\nThe above visualizations are foundational and important. But they’re not the only way to visualize the variables in our dataset.\nOptional Exercise 1: Many Categories\nSuppose we wanted to better understand how the 2020 Republican support varied from county to county within each state. Since repub_pct_20 is quantitative and state_abbr is categorical, we could make a density plot of repub_pct_20 for each state. Reflect on why this is bad.\n\nggplot(elections, aes(x = repub_pct_20, fill = state_abbr)) + \n  geom_density(alpha = 0.5)\n\n\n\n\n\n\n\nA facet wrap would also be bad!\n\nggplot(elections, aes(x = repub_pct_20)) + \n  geom_density(alpha = 0.5) + \n  facet_wrap(~ state_abbr)\n\n\n\n\n\n\n\nWhen we want to compare the distribution of some quantitative outcome among many groups / categories, a ridgeline plot can be a good option. These are also called joy plots, named after the album cover for “Unknown Pleasures” by Joy Division. (Look it up!) To make a ridgeline plot, we can use the geom_density_ridges() function from the ggridges package.\n\n# Install ggridges package\nlibrary(ggridges)\n\n# Make our first joy plot\n# THINK: What DON'T you like about this?\nggplot(elections, aes(x = repub_pct_20, y = state_abbr)) + \n  geom_density_ridges()\n\n\n# Let's put the states in order by Republican support, not alphabet\n# How do you think fct_reorder works? We'll learn about this later in the semester.\nggplot(elections, aes(x = repub_pct_20, y = fct_reorder(state_abbr, repub_pct_20))) + \n  geom_density_ridges(alpha = 0.5)\n\n\n# YOUR TURN: color/fill the ridges according to a state's historical voting patterns \n# and add meaningful axis labels\n\nFollow-up questions\n\nWhich states tend to have the most variability in outcomes from county to county? The least?\nWhat other interesting patterns do you notice?\nDoes this plot prompt any other questions?\nOptional Exercise 2: Total Outcomes by State\nLet’s import some new data and counts up the total votes (Republican and Democratic) by state, not county. This was wrangled from the elections data!\n\nelections_by_state &lt;- read.csv(\"https://mac-stat.github.io/data/election_2020_by_state.csv\")\n\nFor example, we might make a scatterplot of the 2020 vs 2016 outcomes:\n\nggplot(elections_by_state, aes(y = repub_pct_20, x = repub_pct_16)) + \n  geom_point()\n\n\n\n\n\n\n\nBUT this isn’t the easiest way to communicate or identify the changes from 1 year to the next.\n\n# YOU TRY\n# Start by creating a \"scatterplot\" of state_abbr (y-axis) by 2020 Republican support on the x-axis\n# Color the points red\n# Scroll to solutions below when you're ready\n\n\n# Check it out\nggplot(elections_by_state, aes(x = repub_pct_20, y = state_abbr)) + \n  geom_point(color = \"red\")\n\n\n\n\n\n\n\n\n# YOU TRY\n# Reorder the states in terms of their 2020 Republican support (not alphabet)\n# Scroll to solutions below when you're ready\n\n\n# Check it out\nggplot(elections_by_state, aes(x = repub_pct_20, y = fct_reorder(state_abbr, repub_pct_20))) + \n  geom_point(color = \"red\")\n\n\n\n\n\n\n\n\n# Finally, add ANOTHER layer of points for the 2016 outcomes\n# What info does this new geom_point() layer need to run?\nggplot(elections_by_state, aes(x = repub_pct_20, y = fct_reorder(state_abbr, repub_pct_20))) + \n  geom_point(color = \"red\") + \n  geom_point(aes(x = repub_pct_16, y = state_abbr))\n\n\n\n\n\n\n\nReflect on the following\n\nWhat do you think this plot needs? Try it! You might need to do some digging online.\nSummarize the main takeaways from the plots. Which states changed the most from 2016 to 2020? The least? Where did the Republican support increase? Where did it decrease?\nWhat other questions are you left with?",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Bivariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-multi.html",
    "href": "ica/ica-multi.html",
    "title": "\n8  Mulivariate Viz\n",
    "section": "",
    "text": "8.1 Exercises (required)",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Mulivariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-multi.html#exercises-required",
    "href": "ica/ica-multi.html#exercises-required",
    "title": "\n8  Mulivariate Viz\n",
    "section": "",
    "text": "The story\nThough far from a perfect assessment of academic preparedness, SAT scores have historically been used as one measurement of a state’s education system. The education dataset contains various education variables for each state:\n\n# Import and check out data\neducation &lt;- read.csv(\"https://mac-stat.github.io/data/sat.csv\")\nhead(education)\n\n       State expend ratio salary frac verbal math  sat  fracCat\n1    Alabama  4.405  17.2 31.144    8    491  538 1029   (0,15]\n2     Alaska  8.963  17.6 47.951   47    445  489  934 (45,100]\n3    Arizona  4.778  19.3 32.175   27    448  496  944  (15,45]\n4   Arkansas  4.459  17.1 28.934    6    482  523 1005   (0,15]\n5 California  4.992  24.0 41.078   45    417  485  902  (15,45]\n6   Colorado  5.443  18.4 34.571   29    462  518  980  (15,45]\n\n\nA codebook is provided by Danny Kaplan who also made these data accessible:\n\nExercise 1: SAT scores\nPart a\nConstruct a plot of how the average sat scores vary from state to state. (Just use 1 variable – sat not State!)\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nggplot(education, aes(x=sat)) + geom_density()\n\n\n\n\n\n\n\nPart b\nSummarize your observations from the plot. Comment on the basics: range, typical outcomes, shape. (Any theories about what might explain this non-normal shape?)\nThe range is from 840 to 1110. Typical outcome is around 910 and 1030. Shape of the graph is two humps.\nExercise 2: SAT Scores vs Per Pupil Spending & SAT Scores vs Salaries\nThe first question we’d like to answer is: Can the variability in sat scores from state to state be partially explained by how much a state spends on education, specifically its per pupil spending (expend) and typical teacher salary?\nPart a\n\n# Construct a plot of sat vs expend\n# Include a \"best fit linear regression model\" (HINT: method = \"lm\")\nggplot(education, aes(x = sat, y = expend)) + geom_point() + geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n# Construct a plot of sat vs salary\n# Include a \"best fit linear regression model\" (HINT: method = \"lm\")\nggplot(education, aes(x = sat, y = salary)) + geom_point() + geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nPart b\nWhat are the relationship trends between SAT scores and spending? Is there anything that surprises you?\nNegative correlation between SAT score and spending/salary. It is surprising because higher teacher salary might indicate higher education quality?\nExercise 3: SAT Scores vs Per Pupil Spending and Teacher Salaries\nConstruct one visualization of the relationship of sat with salary and expend. HINT: Start with just 2 variables and tweak that code to add the third variable. Try out a few things!\n\nggplot(education, aes(x = sat, y = salary, size = expend)) + geom_point() + geom_smooth(method = \"lm\")\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: The following aesthetics were dropped during statistical transformation: size.\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?\n\n\n\n\n\n\n\n\nExercise 4: Another way to Incorporate Scale\nIt can be tough to distinguish color scales and size scales for quantitative variables. Another option is to discretize a quantitative variable, or basically cut it up into categories.\nConstruct the plot below. Check out the code and think about what’s happening here. What happens if you change “2” to “3”?\n\nggplot(education, aes(y = sat, x = salary, color = cut(expend, 3))) + \n  geom_point() + \n  geom_smooth(se = FALSE, method = \"lm\")\n\nDescribe the trivariate relationship between sat, salary, and expend.\nsat/salary is positively correlated to expend.\nExercise 5: Finally an Explanation\nIt’s strange that SAT scores seem to decrease with spending. But we’re leaving out an important variable from our analysis: the fraction of a state’s students that actually take the SAT. The fracCat variable indicates this fraction: low (under 15% take the SAT), medium (15-45% take the SAT), and high (at least 45% take the SAT).\nPart a\nBuild a univariate viz of fracCat to better understand how many states fall into each category.\n\nggplot(education, aes(x = fracCat)) + geom_bar()\n\n\n\n\n\n\n\nPart b\nBuild 2 bivariate visualizations that demonstrate the relationship between sat and fracCat. What story does your graphic tell and why does this make contextual sense?\n\nggplot(education, aes(x = fracCat, y = sat)) + geom_boxplot()\n\n\n\n\n\n\n\nSAT score is negatively correlated to the percentage of students who take SAT.\nPart c\nMake a trivariate visualization that demonstrates the relationship of sat with expend AND fracCat. Highlight the differences in fracCat groups through color AND unique trend lines. What story does your graphic tell?\nDoes it still seem that SAT scores decrease as spending increases?\n\nggplot(education, aes(x = expend, y = sat, color = fracCat)) + geom_point() + geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nPart d\nPutting all of this together, explain this example of Simpson’s Paradox. That is, why did it appear that SAT scores decrease as spending increases even though the opposite is true?\nBecause the percentage of students who take SAT is a very important and relevant factor of average SAT score, leaving it out would show the trend to be otherwise.",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Mulivariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-multi.html#exercises-optional",
    "href": "ica/ica-multi.html#exercises-optional",
    "title": "\n8  Mulivariate Viz\n",
    "section": "\n8.2 Exercises (optional)",
    "text": "8.2 Exercises (optional)\nExercise 6: Heat Maps\nAs usual, we’ve only just scratched the surface! There are lots of other data viz techniques for exploring multivariate relationships. Let’s start with a heat map.\nPart a\nRun the chunks below. Check out the code, but don’t worry about every little detail! NOTES:\n\nThis is not part of the ggplot() grammar, making it a bit complicated.\nIf you’re curious about what a line in the plot does, comment it out (#) and check out what happens!\nIn the plot, for each state (row), each variable (column) is scaled to indicate whether the state has a relative high value (yellow), a relatively low value (purple), or something in between (blues/greens).\nYou can also play with the color scheme. Type ?cm.colors in the console to learn about various options.\nWe’ll improve the plot later, so don’t spend too much time trying to learn something from this plot.\n\n\n# Remove the \"State\" column and use it to label the rows\n# Then scale the variables\nplot_data &lt;- education |&gt; \n  column_to_rownames(\"State\") |&gt; \n  data.matrix() |&gt; \n  scale()\n\n# Load the gplots package needed for heatmaps\nlibrary(gplots)\n\n# Construct heatmap 1\nheatmap.2(plot_data,\n  dendrogram = \"none\",\n  Rowv = NA, \n  scale = \"column\",\n  keysize = 0.7, \n  density.info = \"none\",\n  col = hcl.colors(256), \n  margins = c(10, 20),\n  colsep = c(1:7), rowsep = (1:50), sepwidth = c(0.05, 0.05),\n  sepcolor = \"white\", trace = \"none\"\n)\n\n\n# Construct heatmap 2\nheatmap.2(plot_data,\n  dendrogram = \"none\",\n  Rowv = TRUE,             ### WE CHANGED THIS FROM NA TO TRUE\n  scale = \"column\",\n  keysize = 0.7, \n  density.info = \"none\",\n  col = hcl.colors(256), \n  margins = c(10, 20),\n  colsep = c(1:7), rowsep = (1:50), sepwidth = c(0.05, 0.05),\n  sepcolor = \"white\", trace = \"none\"\n)\n\n\n# Construct heatmap 3\nheatmap.2(plot_data,\n  dendrogram = \"row\",       ### WE CHANGED THIS FROM \"none\" TO \"row\"\n  Rowv = TRUE,            \n  scale = \"column\",\n  keysize = 0.7, \n  density.info = \"none\",\n  col = hcl.colors(256), \n  margins = c(10, 20),\n  colsep = c(1:7), rowsep = (1:50), sepwidth = c(0.05, 0.05),\n  sepcolor = \"white\", trace = \"none\"\n)\n\nPart b\nIn the final two plots, the states (rows) are rearranged by similarity with respect to these education metrics. The final plot includes a dendrogram which further indicates clusters of similar states. In short, states that have a shorter path to connection are more similar than others.\nPutting this all together, what insight do you gain about the education trends across U.S. states? Which states are similar? In what ways are they similar? Are there any outliers with respect to 1 or more of the education metrics?\nGeographically, the closer the states to each other, the more similiar their eductation. Minnesota, Wisconsin, Illinois are very similar to each other in terms of spending and sat etc, with Michigan being less similar. California and Utah have very high “ratio”.\nExercise 7: Star plots\nLike heat maps, star plots indicate the relative scale of each variable for each state. Thus, we can use star maps to identify similar groups of states, and unusual states!\nPart a\nConstruct and check out the star plot below. Note that each state has a “pie”, with each segment corresponding to a different variable. The larger a segment, the larger that variable’s value is in that state. For example:\n\nCheck out Minnesota. How does Minnesota’s education metrics compare to those in other states? What metrics are relatively high? Relatively low?\nWhat states appear to be similar? Do these observations agree with those that you gained from the heat map?\n\n\nstars(plot_data,\n  flip.labels = FALSE,\n  key.loc = c(10, 1.5),\n  cex = 1, \n  draw.segments = TRUE\n)\n\nPart b\nFinally, let’s plot the state stars by geographic location! What new insight do you gain here?!\n\nstars(plot_data,\n  flip.labels = FALSE,\n  locations = data.matrix(as.data.frame(state.center)),  # added external data to arrange by geo location\n  key.loc = c(-110, 28),\n  cex = 1, \n  draw.segments = TRUE\n)",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Mulivariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-spatial.html",
    "href": "ica/ica-spatial.html",
    "title": "\n9  Spatial Viz\n",
    "section": "",
    "text": "9.1 Exercises",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Spatial Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-spatial.html#exercises",
    "href": "ica/ica-spatial.html#exercises",
    "title": "\n9  Spatial Viz\n",
    "section": "",
    "text": "9.1.1 Preview\nYou’ll explore some R spatial viz tools below. In general, there are two important pieces to every map:\nPiece 1: A dataset\nThis dataset must include either:\n\nlocation coordinates for your points of interest (for point maps); or\nvariable outcomes for your regions of interest (for choropleth maps)\n\n\nPiece 2: A background map\nWe need latitude and longitude coordinates to specify the boundaries for your regions of interest (eg: countries, states). This is where it gets really sticky!\n\nCounty-level, state-level, country-level, continent-level info live in multiple places.\nWhere we grab this info can depend upon whether we want to make a point map or a choropleth map. (The background maps can be used somewhat interchangeably, but it requires extra code :/)\nWhere we grab this info can also depend upon the structure of our data and how much data wrangling / cleaning we’re up for. For choropleth maps, the labels of regions in our data must match those in the background map. For example, if our data labels states with their abbreviations (eg: MN) and the background map refers to them as full names in lower case (eg: minnesota), we have to wrangle our data so that it matches the background map.\n\nIn short, the code for spatial viz gets very specialized. The goal of these exercises is to:\n\nplay around and experience the wide variety of spatial viz tools out there\nunderstand the difference between point maps and choropleth maps\nhave fun\n\nYou can skip around as you wish and it’s totally fine if you don’t finish everything. Just come back at some point to play around.\nPart 1: Interactive points on a map with leaflet\n\nLeaflet is an open-source JavaScript library for creating maps. We can use it inside R through the leaflet package.\nThis uses a different plotting framework than ggplot2, but still has a tidyverse feel (which will become more clear as we learn other tidyverse tools!).\nThe general steps are as follows:\n\nCreate a map widget by calling leaflet() and telling it the data to use.\nAdd a base map using addTiles() (the default) or addProviderTiles().\nAdd layers to the map using layer functions (e.g. addMarkers(), addPolygons()).\nPrint the map widget to display it.\nExercise 1: A leaflet with markers / points\nEarlier this semester, I asked for the latitude and longitude of one of your favorite places. I rounded these to the nearest whole number, so that they’re near to but not exactly at those places. Let’s load the data and map it!\n\nfave_places &lt;- read.csv(\"https://hash-mac.github.io/stat112site-s25/data/our_fave_places.csv\")\n\n# Check it out\nhead(fave_places)\n\nPart a\nYou can use a “two-finger scroll” to zoom in and out.\n\n# Load the leaflet package\nlibrary(leaflet)\nfave_places &lt;- read.csv(\"https://hash-mac.github.io/stat112site-s25/data/our_fave_places.csv\")\n\n# Just a plotting frame\nleaflet(data = fave_places)\n\n\n\n\n\n\n# Now what do we have?\n# A world map\nleaflet(data = fave_places) |&gt; \n  addTiles()\n\n\n\n\n\n\n# Now what do we have?\n# longitude and latitude refer to the variables in our data\n# We have all dots from the data plotted on the map\nleaflet(data = fave_places) |&gt; \n  addTiles() |&gt; \n  addMarkers(lng = ~longitude, lat = ~latitude)\n\n\n\n\n\n\n# Since we named them \"longitude\" and \"latitude\", the function\n# automatically recognizes these variables. No need to write them!\nleaflet(data = fave_places) |&gt; \n  addTiles() |&gt; \n  addMarkers()\n\n\n\n\n\nPart b\nPLAY AROUND! This map is interactive. Zoom in on one location. Keep zooming – what level of detail can you get into? How does that detail depend upon where you try to zoom in (thus what are the limitations of this tool)?\nDetails go up to street and buildings which is very precise. The more populated the place, the more details. No detail on ocean.\nExercise 2: Details\nWe can change all sorts of details in leaflet maps.\n\n# Load package needed to change color\nlibrary(gplots)\n\n\nAttaching package: 'gplots'\n\n\nThe following object is masked from 'package:stats':\n\n    lowess\n\n# We can add colored circles instead of markers at each location\nleaflet(data = fave_places) |&gt; \n  addTiles() |&gt; \n  addCircles(color = col2hex(\"red\"))\n\n\n\n\n\n\n# We can change the background\n# Mark locations with yellow dots\n# And connect the dots, in their order in the dataset, with green lines\n# (These green lines don't mean anything here, but would if this were somebody's travel path!)\nleaflet(data = fave_places) |&gt;\n  addProviderTiles(\"USGS\") |&gt;\n  addCircles(weight = 10, opacity = 1, color = col2hex(\"yellow\")) |&gt;\n  addPolylines(\n    lng = ~longitude,\n    lat = ~latitude,\n    color = col2hex(\"green\")\n  )\n\n\n\n\n\nIn general:\n\naddProviderTiles() changes the base map.\nTo explore all available provider base maps, type providers in the console. (Though some don’t work :/)\n\nUse addMarkers() or addCircles() to mark locations. Type ?addControl into the console to pull up a help file which summarizes the aesthetics of these markers and how you can change them. For example:\n\n\nweight = how thick to make the lines, points, pixels\n\nopacity = transparency (like alpha in ggplot2)\ncolors need to be in “hex” form. We used the col2hex() function from the gplots library to do that\n\n\nExercise 3: Your turn\nThe starbucks data, compiled by Danny Kaplan, contains information about every Starbucks in the world at the time the data were collected, including Latitude and Longitude:\n\n# Import starbucks location data\nstarbucks &lt;- read.csv(\"https://mac-stat.github.io/data/starbucks.csv\")\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nLet’s focus on only those in Minnesota for now:\n\n# Don't worry about the syntax\nstarbucks_mn &lt;- starbucks |&gt;   \n  filter(Country == \"US\", State.Province == \"MN\")\n\nCreate a leaflet map of the Starbucks locations in Minnesota.\n\nleaflet(data = starbucks_mn) |&gt; \n  addTiles() |&gt; \n  addMarkers()\n\nAssuming \"Longitude\" and \"Latitude\" are longitude and latitude, respectively\n\n\n\n\n\n\nKeep it simple – go back to Exercise 1 for an example.\nPart 2: Static points on a map\nLeaflet is very powerful and fun. But:\n\nIt’s not great when we have lots of points to map – it takes lots of time.\nIt makes good interactive maps, but we often need a static map (eg: we can not print interactive maps!).\n\nLet’s explore how to make point maps with ggplot(), not leaflet().\nExercise 3: A simple scatterplot\nLet’s start with the ggplot() tools we already know. Construct a scatterplot of all starbucks locations, not just those in Minnesota, with:\n\nLatitude and Longitude coordinates (which goes on the y-axis?!)\nMake the points transparent (alpha = 0.2) and smaller (size = 0.2)\n\nIt’s pretty cool that the plots we already know can provide some spatial context. But what don’t you like about this plot?\nThere’s no map\n\nggplot(starbucks, aes(x = Longitude, y = Latitude)) + geom_point(alpha = 0.2, size = 0.2)\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\nExercise 4: Adding a country-level background\nLet’s add a background map of country-level boundaries.\nPart a\nFirst, we can grab country-level boundaries from the rnaturalearth package.\n\n# Load the package\nlibrary(rnaturalearth)\n\n# Get info about country boundaries across the world\n# in a \"sf\" or simple feature format\nworld_boundaries &lt;- ne_countries(returnclass = \"sf\")\n\nIn your console, type world_boundaries to check out what’s stored there. Don’t print it our in your Rmd – printing it would be really messy there (even just the head()).\nPart b\nRun the chunks below to build up a new map.\n\n# What does this code produce?\n# What geom are we using for the point map?\n# A world map. geom_sf()\nggplot(world_boundaries) + \n  geom_sf()\n\n\n\n\n\n\n\n\n# Load package needed to change map theme\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\n\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\n\n\nAttaching package: 'mosaic'\n\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\n# Add a point for each Starbucks\n# NOTE: The Starbucks info is in our starbucks data, not world_boundaries\n# How does this change how we use geom_point?!\n# We plot point inside of the ggplot of world_boundaries instead of separately\nggplot(world_boundaries) + \n  geom_sf() + \n  geom_point(\n    data = starbucks,\n    aes(x = Longitude, y = Latitude),\n    alpha = 0.3, size = 0.2, color = \"darkgreen\"\n  ) +\n  theme_map()\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\nPart c\nSummarize what you learned about Starbucks from this map.\nStarbucks are very concentrated in North America, East & SE Asia, and some of Europe. Few location in South America. No Starbucks in Italy. No Starbucks in Antartica, bummer:(\nExercise 5: Zooming in on some countries\nInstead of world_boundaries &lt;- ne_countries(returnclass = 'sf') we could zoom in on…\n\nthe continent of Africa: ne_countries(continent = 'Africa', returnclass = 'sf')\n\na set of countries: ne_countries(country = c('france', 'united kingdom', 'germany'), returnclass = 'sf')\n\nboundaries within a country: ne_states(country = 'united states of america', returnclass = 'sf')\n\n\nOur goal here will be to map the Starbucks locations in Canada, Mexico, and the US.\nPart a\nTo make this map, we again need two pieces of information.\n\nData on Starbucks for only Canada, Mexico, and the US, labeled as “CA”, “MX”, “US” in the starbucks data.\n\n\n# We'll learn this syntax soon! Don't worry about it now.\nstarbucks_cma &lt;- starbucks |&gt; \n  filter(Country %in% c('CA', 'MX', 'US'))\n\n\nA background map of state- and national-level boundaries in Canada, Mexico, and the US. This requires ne_states() in the rnaturalearth package where the countries are labeled ‘canada’, ‘mexico’, ‘united states of america’.\n\n\ncma_boundaries &lt;- ne_states(\n  country = c(\"canada\", \"mexico\", \"united states of america\"),\n  returnclass = \"sf\")\n\nPart b\nMake the map!\n\n# Just the boundaries\nggplot(cma_boundaries) + \n  geom_sf()\n\n\n\n\n\n\n\n\n# Add the points\n# And zoom in\nggplot(cma_boundaries) + \n  geom_sf() + \n  geom_point(\n    data = starbucks_cma,\n    aes(x = Longitude, y = Latitude),\n    alpha = 0.3,\n    size = 0.2,\n    color = \"darkgreen\"\n  ) +\n  coord_sf(xlim = c(-179.14, -50)) +\n  theme_map()\n\n\n\n\n\n\n\nExercise 6: A state and county-level map\nLet’s get an even higher resolution map of Starbucks locations within the states of Minnesota, Wisconsin, North Dakota, and South Dakota, with a background map at the county-level.\nPart a\nTo make this map, we again need two pieces of information.\n\nData on Starbucks for only the states of interest.\n\n\nstarbucks_midwest &lt;- starbucks |&gt; \n  filter(State.Province %in% c(\"MN\", \"ND\", \"SD\", \"WI\"))\n\n\nA background map of state- and county-level boundaries in these states. This requires st_as_sf() in the sf package, and map() in the maps package, where the countries are labeled ‘minnesota’, ‘north dakota’, etc.\n\n\n# Load packages\nlibrary(sf)\n\nLinking to GEOS 3.13.0, GDAL 3.10.1, PROJ 9.5.1; sf_use_s2() is TRUE\n\nlibrary(maps)\n\n\nAttaching package: 'maps'\n\n\nThe following object is masked from 'package:purrr':\n\n    map\n\n# Get the boundaries\nmidwest_boundaries &lt;- st_as_sf(\n  maps::map(\"county\",\n            region = c(\"minnesota\", \"wisconsin\", \"north dakota\", \"south dakota\"), \n            fill = TRUE, plot = FALSE))\n\n# Check it out\nhead(midwest_boundaries)\n\nSimple feature collection with 6 features and 1 field\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -96.81268 ymin: 45.05167 xmax: -93.01397 ymax: 48.53526\nGeodetic CRS:  +proj=longlat +ellps=clrk66 +no_defs +type=crs\n                                     ID                           geom\nminnesota,aitkin       minnesota,aitkin MULTIPOLYGON (((-93.03689 4...\nminnesota,anoka         minnesota,anoka MULTIPOLYGON (((-93.51817 4...\nminnesota,becker       minnesota,becker MULTIPOLYGON (((-95.14537 4...\nminnesota,beltrami   minnesota,beltrami MULTIPOLYGON (((-95.58655 4...\nminnesota,benton       minnesota,benton MULTIPOLYGON (((-93.77027 4...\nminnesota,big stone minnesota,big stone MULTIPOLYGON (((-96.10794 4...\n\n\nPart b\nAdjust the code below to make the plot! Remove the # to run it.\n\n ggplot(midwest_boundaries) + \n   geom_sf() + \n   geom_point(\n     data = starbucks_midwest,\n     aes(x = Longitude, y = Latitude),\n     alpha = 0.7,\n     size = 0.2, \n     color = 'darkgreen'\n   ) + \n   theme_map()\n\n\n\n\n\n\n\nExercise 7: Contour maps\nEspecially when there are lots of point locations, and those locations start overlapping on a map, it can be tough to visualize areas of higher density. Consider the Starbucks locations in Canada, Mexico, and the US that we mapped earlier:\n\n# Point map (we made this earlier)\nggplot(cma_boundaries) + \n  geom_sf() + \n  geom_point(\n    data = starbucks_cma,\n    aes(x = Longitude, y = Latitude),\n    alpha = 0.3,\n    size = 0.2,\n    color = \"darkgreen\"\n  ) +\n  coord_sf(xlim = c(-179.14, -50), ylim = c(14.54, 83.11)) +\n  theme_map()\n\n\n\n\n\n\n\nNow check out the contour map.\n\n# The points became contours.\n# geom_point() became geom_23\nggplot(cma_boundaries) + \n  geom_sf() + \n  geom_density_2d(\n    data = starbucks_cma,\n    aes(x = Longitude, y = Latitude),\n    size = 0.2,\n    color = \"darkgreen\"\n  ) +\n  coord_sf(xlim = c(-179.14, -50), ylim = c(14.54, 83.11)) +\n  theme_map()\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\nPart 3: Choropleth maps\nSpatial data isn’t always in the form of point locations! For example, recall the state and county-level data on presidential elections.\n\nelections_by_state &lt;-  read.csv(\"https://mac-stat.github.io/data/election_2020_by_state.csv\")\nelections_by_counties &lt;- read.csv(\"https://mac-stat.github.io/data/election_2020_county.csv\")\n\nIn these datasets, we’re interested in the overall election outcome by region (state or county), not the specific geographic location of some observation. Let’s wrangle our data first. We’ll focus on just a few variables of interest, and create a new variable (repub_20_categories) that discretizes the repub_pct_20 variable into increments of 5 percentage points (for states) or 10 percentage points (for counties):\n\n# Don't worry about the code!\n\nelections_by_state &lt;- elections_by_state |&gt; \n  filter(state_abbr != \"DC\") |&gt; \n  select(state_name, state_abbr, repub_pct_20) |&gt; \n  mutate(repub_20_categories = \n           cut(repub_pct_20, \n               breaks = seq(30, 70, by = 5), \n               labels = c(\"30-34\", \"35-39\", \"40-44\", \"45-49\",\n                          \"50-54\", \"55-59\", \"60-64\", \"65-70\"), \n               include.lowest = TRUE))\n\nelections_by_counties &lt;- elections_by_counties |&gt; \n  select(state_name, state_abbr, county_name, county_fips,\n          repub_pct_20, median_age, median_rent) |&gt; \n  mutate(repub_20_categories = \n           cut(repub_pct_20, \n               breaks = seq(0, 100, by = 10),\n               labels = c(\"0-9\", \"10-19\", \"20-29\", \"30-39\", \"40-49\",\n                          \"50-59\", \"60-69\", \"70-79\", \"80-89\", \"90-100\"),\n               include.lowest = TRUE))\n\nExercise 8: State-level choropleth maps\nLet’s map the 2020 Republican support in each state, repub_pct_20.\nPart a\nWe again need two pieces of information.\n\nData on elections in each state, which we already have: elections_by_state.\nA background map of state boundaries in the US. The boundaries we used for point maps don’t work here. (Optional detail: they’re sf objects and we now need a data.frame object.) Instead, we can use the map_data() function from the ggplot2 package:\n\n\n# Get the latitude and longitude coordinates of state boundaries\nstates_map &lt;- map_data(\"state\")\n\n# Check it out\nhead(states_map)\n\n       long      lat group order  region subregion\n1 -87.46201 30.38968     1     1 alabama      &lt;NA&gt;\n2 -87.48493 30.37249     1     2 alabama      &lt;NA&gt;\n3 -87.52503 30.37249     1     3 alabama      &lt;NA&gt;\n4 -87.53076 30.33239     1     4 alabama      &lt;NA&gt;\n5 -87.57087 30.32665     1     5 alabama      &lt;NA&gt;\n6 -87.58806 30.32665     1     6 alabama      &lt;NA&gt;\n\n\nPause\nImportant detail: Note that the region variable in states_map, and the state_name variable in elections_by_state both label states by the full name in lower case letters. This is critical to the background map and our data being able to communicate.\n\nhead(states_map)\n\n       long      lat group order  region subregion\n1 -87.46201 30.38968     1     1 alabama      &lt;NA&gt;\n2 -87.48493 30.37249     1     2 alabama      &lt;NA&gt;\n3 -87.52503 30.37249     1     3 alabama      &lt;NA&gt;\n4 -87.53076 30.33239     1     4 alabama      &lt;NA&gt;\n5 -87.57087 30.32665     1     5 alabama      &lt;NA&gt;\n6 -87.58806 30.32665     1     6 alabama      &lt;NA&gt;\n\nhead(elections_by_state) \n\n   state_name state_abbr repub_pct_20 repub_20_categories\n1     alabama         AL        62.03               60-64\n2    arkansas         AR        62.40               60-64\n3     arizona         AZ        49.06               45-49\n4  california         CA        34.33               30-34\n5    colorado         CO        41.90               40-44\n6 connecticut         CT        39.21               35-39\n\n\nPart b\nNow map repub_pct_20 by state.\n\n# Note where the dataset, elections_by_state, is used\n# Note where the background map, states_map, is used\nggplot(elections_by_state, aes(map_id = state_name, fill = repub_pct_20)) +\n  geom_map(map = states_map) +\n  expand_limits(x = states_map$long, y = states_map$lat) +\n  theme_map() \n\n\n\n\n\n\n\n\n# Make it nicer!\nggplot(elections_by_state, aes(map_id = state_name, fill = repub_pct_20)) +\n  geom_map(map = states_map) +\n  expand_limits(x = states_map$long, y = states_map$lat) +\n  theme_map() + \n  scale_fill_gradientn(name = \"% Republican\", colors = c(\"blue\", \"purple\", \"red\"), values = scales::rescale(seq(0, 100, by = 5)))\n\n\n\n\n\n\n\nIt’s not easy to get fine control over the color scale for the quantitative repub_pct_20 variable. Instead, let’s plot the discretized version, repub_20_categories:\n\nggplot(elections_by_state, aes(map_id = state_name, fill = repub_20_categories)) +\n  geom_map(map = states_map) +\n  expand_limits(x = states_map$long, y = states_map$lat) +\n  theme_map()\n\n\n\n\n\n\n\n\n# Load package needed for refining color palette\nlibrary(RColorBrewer)\n\n# Now fix the colors\nggplot(elections_by_state, aes(map_id = state_name, fill = repub_20_categories)) +\n  geom_map(map = states_map) +\n  expand_limits(x = states_map$long, y = states_map$lat) +\n  theme_map() + \n  scale_fill_manual(values = rev(brewer.pal(8, \"RdBu\")), name = \"% Republican\")\n\n\n\n\n\n\n\nPart c\nWe can add other layers, like points, on top of a choropleth map. Add a Starbucks layer! Do you notice any relationship between Starbucks and elections? Or are we just doing things at this point?\n;)\n\n# Get only the starbucks data from the US\nstarbucks_us &lt;- starbucks |&gt; \n  filter(Country == \"US\")\n\n# Map it\nggplot(elections_by_state, aes(map_id = state_name, fill = repub_20_categories)) +\n  geom_map(map = states_map) +\n  geom_point(\n    data = starbucks_us,\n    aes(x = Longitude, y = Latitude),\n    size = 0.05,\n    alpha = 0.2,\n    inherit.aes = FALSE\n  ) +\n  expand_limits(x = states_map$long, y = states_map$lat) +\n  theme_map() + \n  scale_fill_manual(values = rev(brewer.pal(8, \"RdBu\")), name = \"% Republican\")\n\n\n\n\n\n\n\nDetails (if you’re curious)\n\n\nmap_id is a required aesthetic for geom_map().\n\nIt specifies which variable in our dataset indicates the region (here state_name).\nIt connects this variable (state_name) to the region variable in our mapping background (states_map). These variables must have the same possible outcomes in order to be matched up (alabama, alaska, arizona,…).\n\n\n\nexpand_limits() assures that the map covers the entire area it’s supposed to, by pulling longitudes and latitudes from the states_map.\nPart d\nWe used geom_sf() for point maps. What geom do we use for choropleth maps?\ngeom_map()\nExercise 9: County-level choropleth maps\nLet’s map the 2020 Republican support in each county.\nPart a\nWe again need two pieces of information.\n\nData on elections in each county, which we already have: elections_by_county.\nA background map of county boundaries in the US, stored in the county_map dataset in the socviz package:\n\n\n# Get the latitude and longitude coordinates of county boundaries\nlibrary(socviz)\ndata(county_map) \n\n# Check it out\nhead(county_map)\n\n     long      lat order  hole piece            group    id\n1 1225889 -1275020     1 FALSE     1 0500000US01001.1 01001\n2 1235324 -1274008     2 FALSE     1 0500000US01001.1 01001\n3 1244873 -1272331     3 FALSE     1 0500000US01001.1 01001\n4 1244129 -1267515     4 FALSE     1 0500000US01001.1 01001\n5 1272010 -1262889     5 FALSE     1 0500000US01001.1 01001\n6 1276797 -1295514     6 FALSE     1 0500000US01001.1 01001\n\n\nPause\nImportant detail: We officially have a headache. Our county_map refers to each county by a 5-number id. Our elections_by_counties data refers to each county by a county_fips code, which is mostly the same as id, BUT drops any 0’s at the beginning of the code.\n\nhead(county_map)\n\n     long      lat order  hole piece            group    id\n1 1225889 -1275020     1 FALSE     1 0500000US01001.1 01001\n2 1235324 -1274008     2 FALSE     1 0500000US01001.1 01001\n3 1244873 -1272331     3 FALSE     1 0500000US01001.1 01001\n4 1244129 -1267515     4 FALSE     1 0500000US01001.1 01001\n5 1272010 -1262889     5 FALSE     1 0500000US01001.1 01001\n6 1276797 -1295514     6 FALSE     1 0500000US01001.1 01001\n\nhead(elections_by_counties)\n\n  state_name state_abbr    county_name county_fips repub_pct_20 median_age\n1    Alabama         AL Autauga County        1001        71.44       37.5\n2    Alabama         AL Baldwin County        1003        76.17       41.5\n3    Alabama         AL Barbour County        1005        53.45       38.3\n4    Alabama         AL    Bibb County        1007        78.43       39.4\n5    Alabama         AL  Blount County        1009        89.57       39.6\n6    Alabama         AL Bullock County        1011        24.84       39.6\n  median_rent repub_20_categories\n1         668               70-79\n2         693               70-79\n3         382               50-59\n4         351               70-79\n5         403               80-89\n6         276               20-29\n\n\nThis just means that we have to wrangle the data so that it can communicate with the background map.\n\n# Add 0's at the beginning of any fips_code that's fewer than 5 numbers long\n# Don't worry about the syntax\nelections_by_counties &lt;- elections_by_counties |&gt; \n  mutate(county_fips = as.character(county_fips)) |&gt; \n  mutate(county_fips = \n           ifelse(nchar(county_fips) == 4, paste0(\"0\", county_fips), county_fips))\n\nPart b\nNow map Republican support by county. Let’s go straight to the discretized repub_20_categories variable, and a good color scale.\n\nggplot(elections_by_counties, aes(map_id = county_fips, fill = repub_20_categories)) +\n  geom_map(map = county_map) +\n  scale_fill_manual(values = rev(brewer.pal(10, \"RdBu\")), name = \"% Republican\") +\n  expand_limits(x = county_map$long, y = county_map$lat) +\n  theme_map() +\n  theme(legend.position = \"right\") + \n  coord_equal()\n\n\n\n\n\n\n\nExercise 10: Play around!\nConstruct county-level maps of median_rent and median_age.\n\nggplot(elections_by_counties, aes(map_id = county_fips, fill = median_rent)) +\n  geom_map(map = county_map) +\n  scale_fill_gradient(low = \"red\", high = \"yellow\", name = \"Median Rent\") +\n  expand_limits(x = county_map$long, y = county_map$lat) +\n  theme_map() +\n  theme(legend.position = \"right\") + \n  coord_equal()\n\n\n\n\n\n\n\n\nggplot(elections_by_counties, aes(map_id = county_fips, fill = median_age)) +\n  geom_map(map = county_map) +\n  scale_fill_gradient(low = \"red\", high = \"yellow\", name = \"Median Age\") +\n  expand_limits(x = county_map$long, y = county_map$lat) +\n  theme_map() +\n  theme(legend.position = \"right\") + \n  coord_equal()\n\n\n\n\n\n\n\nExercise 11: Choropleth maps with leaflet\nThough ggplot() is often better for this purpose, we can also make choropleth maps with leaflet(). If you’re curious, check out the leaflet documentation:\nhttps://rstudio.github.io/leaflet/choropleths.html",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Spatial Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-effective.html",
    "href": "ica/ica-effective.html",
    "title": "\n10  Effective Viz\n",
    "section": "",
    "text": "10.1 Exercises",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Effective Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-effective.html#exercises",
    "href": "ica/ica-effective.html#exercises",
    "title": "\n10  Effective Viz\n",
    "section": "",
    "text": "Exercise 1: Professionalism\nLet’s examine weather in 3 Australian locations.\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nThe following plot is fine for things like homework or just playing around. But we’ll make it more “professional” looking below.\n\nggplot(weather, aes(y = temp3pm, x = temp9am, color = location)) + \n  geom_point()\n\nWarning: Removed 27 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\nPart a\nReplace A, B, C, and D in the code below to:\n\nAdd a short, but descriptive title. Under 10 words.\nChange the x- and y-axis labels, currently just the names of the variables in the dataset. These should be short and include units.\nChange the legend title to “Location” (just for practice, not because it’s better than “location”).\n\n\nggplot(weather, aes(y = temp3pm, x = temp9am, color = location)) + \n  geom_point() + \n  labs(x = \"9 AM Temperature (°C)\", y = \"3 PM Temperature (°C)\", title = \"Temperature at 9AM and 3PM at same location\", color = \"Legend\")\n\nWarning: Removed 27 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\nPart b\nWhen we’re including our plot in an article, paper, book, or other similar outlet, we should (and are expected to) provide a more descriptive figure caption. Typically, this is instead of a title and is more descriptive of what exactly is being plotted.\n\nAdd a figure caption in the top of the chunk.\nInclude your x-axis, y-axis, and legend labels from Part a.\nRender your Rmd and check out how the figure caption appears.\n\n\nggplot(weather, aes(y = temp3pm, x = temp9am, color = location, size = rainfall)) + \n  geom_point() + \n  labs(x = \"9 AM Temperature (°C)\", y = \"3 PM Temperature (°C)\", color = \"Island\", size = \"Rainfall (mm)\")  \n\nWarning: Removed 69 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\nTemperature at 9AM and 3PM shows positive correlation\n\n\n\n\nExercise 2: Accessibility\nLet’s now make a graphic more accessible.\n\nggplot(weather, aes(x = temp3pm, fill = location)) + \n  geom_density(alpha = 0.5) + \n  labs(x = \"3pm temperature (Celsius)\")  \n\nWarning: Removed 19 rows containing non-finite outside the scale range\n(`stat_density()`).\n\n\n\n\nDensity plots of 3pm temperatures in 3 Australian locations.\n\n\n\nPart a\nLet’s add some alt text that can be picked up by screen readers. This is a great resource on writing alt text for data viz. In short, whereas figure captions are quick descriptions which assume that the viz is accessible, alt text is a longer description which assumes the viz is not accessible. Alt text should concisely articulate:\n\nWhat your visualization is (e.g. a density plot of 3pm temperatures in Hobart, Uluru, and Wollongong, Australia).\nA 1-sentence description of the most important takeaway.\nA link to your data source if it’s not already in the caption.\n\nAdd appropriate alt text at the top of the chunk, in fig-alt. Then knit your Rmd, and hover over the image in your knitted html file to check out the alt text.\n\nggplot(weather, aes(x = temp3pm, fill = location)) + \n  geom_density(alpha = 0.5) + \n  labs(x = \"3pm temperature (Celsius)\")  \n\nWarning: Removed 19 rows containing non-finite outside the scale range\n(`stat_density()`).\n\n\n\n\nDensity plots of 3pm temperatures in 3 Australian locations.\n\n\n\n\nPart b\nColor is another important accessibility consideration. Let’s check out the color accessibility of our density plot.\n\nRun the ggplot() code from Part a in your console. The viz will pop up in the Plots tab.\nIn the Plots tab, click “Export” then “Save as image”. Save the image somewhere.\nNavigate to https://www.color-blindness.com/coblis-color-blindness-simulator/\n\nAbove the image of crayons (I think it’s crayons?), click “Choose file” and choose the plot file you just saved.\nClick the various simulator buttons (eg: Red-Weak/Protanomaly) to check out how the colors in this plot might appear to others.\nSummarize what you learn. What impact might our color choices have on one’s ability to interpret the viz?\n\nFor color weakness, color scale might affect the understanding. For one-color blindness, inappropriate color scale can be confusing. We shall use color scales that are friendly to colorblind people.\nPart c\nWe can change our color schemes! There are many color-blind friendly palettes in R. In the future, we’ll set a default, more color-blind friendly color theme at the top of our Rmds. We can also do this individually for any plot that uses color. Run the chunks below to explore various options.\n\nggplot(weather, aes(x = temp3pm, fill = location)) + \n  geom_density(alpha = 0.5) + \n  labs(x = \"3pm temperature (Celsius)\") + \n  scale_fill_viridis_d()    \n\nWarning: Removed 19 rows containing non-finite outside the scale range\n(`stat_density()`).\n\n\n\n\n\n\n\n\n\n# In the color scale line:\n# Change \"fill\" to \"color\" since we use color in the aes()\n# Change \"d\" (discrete) to \"c\" (continuous) since maxtemp is on a continuous scale\nggplot(weather, aes(y = temp3pm, x = temp9am, color = maxtemp)) + \n  geom_point(alpha = 0.5) + \n  labs(x = \"3pm temperature (Celsius)\") + \n  scale_color_viridis_c()\n\nWarning: Removed 27 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nExercise 3: Ethics\nLet’s scratch the surface of ethics in data viz. Central to this discussion is the consideration of impact.\nPart a\nAt a minimum, our data viz should not mislead. Reconsider the climate change example from above. Why is this plot unethical and what impact might it have on policy, public opinion, etc?\n\nPart b\nAgain, data viz ethical considerations go beyond whether or not a plot is misleading. As described in the warm-up, we need to consider: visibility, privacy, power, emotion & embodiment, pluralism, & context. Depending upon the audience and goals of a data viz, addressing these points might require more nuance. Mainly, the viz tools we’ve learned are a great base or foundation, but aren’t the only approaches to data viz. \nPick one or more of the following examples of data viz to discuss with your group. How do the approaches taken:\n\nemphasize one or more of: visibility, privacy, power, emotion, embodiment, pluralism, and/or context?\nimprove upon what we might be able to convey with a simpler bar chart, scatterplot, etc?\n\n\nExample: W.E.B. Du Bois (1868–1963)\nDu Bois (“Doo Boys”) was a “sociologist, socialist, historian, civil rights activist, Pan-Africanist, author, writer, and editor”1. He was also a pioneer in elevating emotion and embodiment in data visualization. For the Paris World Fair of 1900, Du Bois and his team of students from Atlanta University presented 60 data visualizations of the Black experience in America, less than 50 years after the abolishment of slavery. Du Bois noted: “I wanted to set down its aim and method in some outstanding way which would bring my work to notice by the thinking world.” That is, he wanted to increase the impact of his work by partnering technical visualizations with design that better connects to lived experiences. NOTE: This work uses language common to that time period and addresses the topic of slavery. Check out:\n\nA complete set of the data visualizations provided by Anthony Starks (@ajstarks).\nAn article by Allen Hillery (@AlDatavizguy).\n\n\nExample: One person’s experience with long COVID\nNYT article\n\nExample: Decolonizing data viz\nblog post\n\nExample: Visualizing climate change through art\nFutures North with Prof John Kim & Mac students (by Prof Kim, Mac research students)\n\nExample: Personal data collection\nDear Data\n\nPart c\nFor a deeper treatment of similar topics, and more examples, read Data Feminism.\n\nExercise 4: Critique\nPractice critiquing some more complicated data viz listed at Modern Data Science with R, Exercise 2.5.\nThink about the following questions:\n\nWhat story does the data graphic tell? What is the main message that you take away from it?\nCan the data graphic be described in terms of the Grammar of Graphics (frame, glyphs, aesthetics, facet, scale, guide)? If so, please describe.\nCritique and/or praise the visualization choices made by the designer. Do they work? Are they misleading? Thought-provoking? Are there things that you would have done differently?\n\n\nExercise 5: Design Details\nThis final exercise is just “food for thought”. It’s more of a discussion than an exercise, and gets into some of the finer design details and data viz theory. Go as deep or not deep as you’d like here.\nIn refining the details of our data viz, Visualize This and Storytelling with Data provide some of their guiding principles. But again, every context is different.\n\nPut yourself in a reader’s shoes. What parts of the data need explanation?\nShine a light on your data. Try to remove any “chart junk” that distracts from the data.\nVary color and style to emphasize the viz elements that are most important to the story you’re telling.\nIt is easier to judge length than it is to judge area or angles.\nBe thoughtful about how your categories are ordered for categorical data.\n\nGetting into even more of the nitty gritty, we need to be mindful of what geometric elements and aesthetics we use. The following elements/aesthetics are listed in roughly descending order of human ability to perceive and compare nearby objects:2\n\nPosition\nLength\nAngle\nDirection\nShape (but only a very few different shapes)\nArea\nVolume\nShade\nColor. (Color is the most difficult, because it is a 3-dimensional quantity.)\n\nFinally, here are some facts to keep in mind about visual perception from Now You See It.\nPart a: Selectivity\nVisual perception is selective, and our attention is often drawn to contrasts from the norm.\nImplication: We should design visualizations so that the features we want to highlight stand out in contrast from those that are not worth the audience’s attention.\nExample: What stands out in this example image? This is originally from C. Ware, Information Visualization: Perception for Design, 2004? Source: S. Few, Now You See It, 2009, p. 33.\n\nPart b: Familiarity\nOur eyes are drawn to familiar patterns. We observe what we know and expect.\nImplication: Visualizations work best when they display information as patterns that familiar and easy to spot.\nExample: Do you notice anything embedded in this rose image from coolbubble.com? Source: S. Few, Now You See It, 2009, p. 34.\n\nPart c: Revisit\nRevisit Part b. Do you notice anything in the shadows? Go to https://mac-stat.github.io/images/112/rose2.png for an image.\n\nWrapping up\nIf you finish early:\n\nWork on homework if not done already\nComplete any activities you haven’t finished yet, eg, spatial viz, the optional but fun exercises in the Multivariate viz and Bivariate viz activities.\nIf you’ve done all that, explore some datasets in TidyTuesday.",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Effective Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-effective.html#footnotes",
    "href": "ica/ica-effective.html#footnotes",
    "title": "\n10  Effective Viz\n",
    "section": "",
    "text": "https://en.wikipedia.org/wiki/W._E._B._Du_Bois↩︎\nB. S. Baumer, D. T. Kaplan, and N. J. Horton, Modern Data Science with R, 2017, p. 15.↩︎",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Effective Viz</span>"
    ]
  }
]